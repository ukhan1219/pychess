{
  "best_global_step": 30000,
  "best_metric": 0.2560758888721466,
  "best_model_checkpoint": "models/reward_model_targeted/checkpoint-30000",
  "epoch": 1.6,
  "eval_steps": 2500,
  "global_step": 30000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 12.709643363952637,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.4647,
      "step": 250
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 5.369814872741699,
      "learning_rate": 4.99e-05,
      "loss": 0.3556,
      "step": 500
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.8601644039154053,
      "learning_rate": 7.49e-05,
      "loss": 0.3547,
      "step": 750
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 4.946514129638672,
      "learning_rate": 9.99e-05,
      "loss": 0.3399,
      "step": 1000
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 3.728809118270874,
      "learning_rate": 9.998851750946687e-05,
      "loss": 0.3375,
      "step": 1250
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.4466159343719482,
      "learning_rate": 9.995389071847602e-05,
      "loss": 0.3253,
      "step": 1500
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 1.1959017515182495,
      "learning_rate": 9.989613547388903e-05,
      "loss": 0.3159,
      "step": 1750
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 1.864534854888916,
      "learning_rate": 9.981527851615542e-05,
      "loss": 0.3,
      "step": 2000
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.3759591579437256,
      "learning_rate": 9.971135728172647e-05,
      "loss": 0.3118,
      "step": 2250
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 1.5684226751327515,
      "learning_rate": 9.958441988572221e-05,
      "loss": 0.3142,
      "step": 2500
    },
    {
      "epoch": 0.13333333333333333,
      "eval_accuracy": 0.8615042741887049,
      "eval_loss": 0.3051988184452057,
      "eval_runtime": 106.6487,
      "eval_samples_per_second": 468.829,
      "eval_steps_per_second": 23.441,
      "step": 2500
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 4.751043319702148,
      "learning_rate": 9.943452509965432e-05,
      "loss": 0.3091,
      "step": 2750
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.5801117420196533,
      "learning_rate": 9.926174232421521e-05,
      "loss": 0.3063,
      "step": 3000
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 1.4850915670394897,
      "learning_rate": 9.906615155714574e-05,
      "loss": 0.2987,
      "step": 3250
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 1.841718316078186,
      "learning_rate": 9.884784335619656e-05,
      "loss": 0.2941,
      "step": 3500
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.755624294281006,
      "learning_rate": 9.860691879720028e-05,
      "loss": 0.2981,
      "step": 3750
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 1.0241472721099854,
      "learning_rate": 9.834348942727366e-05,
      "loss": 0.2894,
      "step": 4000
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 2.776632070541382,
      "learning_rate": 9.805767721317188e-05,
      "loss": 0.2919,
      "step": 4250
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3648786544799805,
      "learning_rate": 9.77496144848183e-05,
      "loss": 0.286,
      "step": 4500
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 2.97837495803833,
      "learning_rate": 9.74194438740363e-05,
      "loss": 0.2954,
      "step": 4750
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 2.7456305027008057,
      "learning_rate": 9.706731824851128e-05,
      "loss": 0.299,
      "step": 5000
    },
    {
      "epoch": 0.26666666666666666,
      "eval_accuracy": 0.8690132948902771,
      "eval_loss": 0.29283827543258667,
      "eval_runtime": 106.7696,
      "eval_samples_per_second": 468.298,
      "eval_steps_per_second": 23.415,
      "step": 5000
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1400375366210938,
      "learning_rate": 9.669340064101349e-05,
      "loss": 0.2957,
      "step": 5250
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 1.9680818319320679,
      "learning_rate": 9.62978641739146e-05,
      "loss": 0.2895,
      "step": 5500
    },
    {
      "epoch": 0.30666666666666664,
      "grad_norm": 1.022106647491455,
      "learning_rate": 9.588089197903261e-05,
      "loss": 0.2998,
      "step": 5750
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1005579233169556,
      "learning_rate": 9.544267711284265e-05,
      "loss": 0.3025,
      "step": 6000
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.9404424428939819,
      "learning_rate": 9.498342246709251e-05,
      "loss": 0.2907,
      "step": 6250
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 1.5248626470565796,
      "learning_rate": 9.450334067486466e-05,
      "loss": 0.2924,
      "step": 6500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.6530020236968994,
      "learning_rate": 9.400265401212785e-05,
      "loss": 0.2899,
      "step": 6750
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.930081307888031,
      "learning_rate": 9.348159429482433e-05,
      "loss": 0.2861,
      "step": 7000
    },
    {
      "epoch": 0.38666666666666666,
      "grad_norm": 1.1193532943725586,
      "learning_rate": 9.294040277153992e-05,
      "loss": 0.3079,
      "step": 7250
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.110487699508667,
      "learning_rate": 9.237933001180691e-05,
      "loss": 0.2984,
      "step": 7500
    },
    {
      "epoch": 0.4,
      "eval_accuracy": 0.8715206856502062,
      "eval_loss": 0.28327515721321106,
      "eval_runtime": 106.9494,
      "eval_samples_per_second": 467.511,
      "eval_steps_per_second": 23.376,
      "step": 7500
    },
    {
      "epoch": 0.41333333333333333,
      "grad_norm": 1.767709732055664,
      "learning_rate": 9.179863579009133e-05,
      "loss": 0.2855,
      "step": 7750
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 1.414985179901123,
      "learning_rate": 9.119858896551841e-05,
      "loss": 0.292,
      "step": 8000
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0420770645141602,
      "learning_rate": 9.057946735739187e-05,
      "loss": 0.2915,
      "step": 8250
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 2.6279079914093018,
      "learning_rate": 8.994155761656468e-05,
      "loss": 0.2823,
      "step": 8500
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 1.4486325979232788,
      "learning_rate": 8.928515509272089e-05,
      "loss": 0.2978,
      "step": 8750
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.605020046234131,
      "learning_rate": 8.861056369762979e-05,
      "loss": 0.2837,
      "step": 9000
    },
    {
      "epoch": 0.49333333333333335,
      "grad_norm": 1.0214515924453735,
      "learning_rate": 8.79180957644361e-05,
      "loss": 0.2853,
      "step": 9250
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 1.615809679031372,
      "learning_rate": 8.720807190305085e-05,
      "loss": 0.2727,
      "step": 9500
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8467230796813965,
      "learning_rate": 8.648082085171033e-05,
      "loss": 0.2798,
      "step": 9750
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.6112866401672363,
      "learning_rate": 8.573667932477156e-05,
      "loss": 0.2769,
      "step": 10000
    },
    {
      "epoch": 0.5333333333333333,
      "eval_accuracy": 0.8731137173277829,
      "eval_loss": 0.28037694096565247,
      "eval_runtime": 105.7074,
      "eval_samples_per_second": 473.004,
      "eval_steps_per_second": 23.65,
      "step": 10000
    },
    {
      "epoch": 0.5466666666666666,
      "grad_norm": 2.2006828784942627,
      "learning_rate": 8.497599185681487e-05,
      "loss": 0.2788,
      "step": 10250
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8232274055480957,
      "learning_rate": 8.419911064312575e-05,
      "loss": 0.2727,
      "step": 10500
    },
    {
      "epoch": 0.5733333333333334,
      "grad_norm": 0.9582101106643677,
      "learning_rate": 8.34063953766299e-05,
      "loss": 0.2702,
      "step": 10750
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 2.351168155670166,
      "learning_rate": 8.259821308135667e-05,
      "loss": 0.2863,
      "step": 11000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7015001177787781,
      "learning_rate": 8.177493794250861e-05,
      "loss": 0.2881,
      "step": 11250
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 1.385895013809204,
      "learning_rate": 8.093695113321498e-05,
      "loss": 0.2736,
      "step": 11500
    },
    {
      "epoch": 0.6266666666666667,
      "grad_norm": 1.061233401298523,
      "learning_rate": 8.008464063805023e-05,
      "loss": 0.2696,
      "step": 11750
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2192528247833252,
      "learning_rate": 7.921840107339868e-05,
      "loss": 0.2725,
      "step": 12000
    },
    {
      "epoch": 0.6533333333333333,
      "grad_norm": 0.939819872379303,
      "learning_rate": 7.833863350474864e-05,
      "loss": 0.2831,
      "step": 12250
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.2785474061965942,
      "learning_rate": 7.744574526100069e-05,
      "loss": 0.2673,
      "step": 12500
    },
    {
      "epoch": 0.6666666666666666,
      "eval_accuracy": 0.874904912519518,
      "eval_loss": 0.27883896231651306,
      "eval_runtime": 106.5333,
      "eval_samples_per_second": 469.337,
      "eval_steps_per_second": 23.467,
      "step": 12500
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9156312942504883,
      "learning_rate": 7.654014974587607e-05,
      "loss": 0.2686,
      "step": 12750
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 1.0805211067199707,
      "learning_rate": 7.562226624651229e-05,
      "loss": 0.269,
      "step": 13000
    },
    {
      "epoch": 0.7066666666666667,
      "grad_norm": 0.9786542057991028,
      "learning_rate": 7.469251973933498e-05,
      "loss": 0.2633,
      "step": 13250
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7949926257133484,
      "learning_rate": 7.375134069329532e-05,
      "loss": 0.26,
      "step": 13500
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 1.0003505945205688,
      "learning_rate": 7.27991648705648e-05,
      "loss": 0.2602,
      "step": 13750
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.7489634156227112,
      "learning_rate": 7.183643312477893e-05,
      "loss": 0.2792,
      "step": 14000
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.9031078815460205,
      "learning_rate": 7.086359119692378e-05,
      "loss": 0.2723,
      "step": 14250
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.9618170857429504,
      "learning_rate": 6.988108950895972e-05,
      "loss": 0.2776,
      "step": 14500
    },
    {
      "epoch": 0.7866666666666666,
      "grad_norm": 1.0869135856628418,
      "learning_rate": 6.88893829552778e-05,
      "loss": 0.2754,
      "step": 14750
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.997846245765686,
      "learning_rate": 6.788893069208542e-05,
      "loss": 0.2753,
      "step": 15000
    },
    {
      "epoch": 0.8,
      "eval_accuracy": 0.876891361780482,
      "eval_loss": 0.27363863587379456,
      "eval_runtime": 106.4167,
      "eval_samples_per_second": 469.851,
      "eval_steps_per_second": 23.493,
      "step": 15000
    },
    {
      "epoch": 0.8133333333333334,
      "grad_norm": 2.172363758087158,
      "learning_rate": 6.688019592481885e-05,
      "loss": 0.2574,
      "step": 15250
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 1.1191976070404053,
      "learning_rate": 6.5863645693681e-05,
      "loss": 0.2706,
      "step": 15500
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9212710857391357,
      "learning_rate": 6.483975065740353e-05,
      "loss": 0.2807,
      "step": 15750
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 2.532834529876709,
      "learning_rate": 6.380898487533387e-05,
      "loss": 0.267,
      "step": 16000
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 0.8673630952835083,
      "learning_rate": 6.277182558794748e-05,
      "loss": 0.2766,
      "step": 16250
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.682296633720398,
      "learning_rate": 6.172875299588752e-05,
      "loss": 0.2593,
      "step": 16500
    },
    {
      "epoch": 0.8933333333333333,
      "grad_norm": 0.7324514389038086,
      "learning_rate": 6.0680250037633754e-05,
      "loss": 0.2657,
      "step": 16750
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.9575427770614624,
      "learning_rate": 5.962680216590405e-05,
      "loss": 0.2552,
      "step": 17000
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9194244146347046,
      "learning_rate": 5.856889712289153e-05,
      "loss": 0.2736,
      "step": 17250
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.810340404510498,
      "learning_rate": 5.7507024714442105e-05,
      "loss": 0.2794,
      "step": 17500
    },
    {
      "epoch": 0.9333333333333333,
      "eval_accuracy": 0.8792968828204769,
      "eval_loss": 0.2699310779571533,
      "eval_runtime": 106.1309,
      "eval_samples_per_second": 471.117,
      "eval_steps_per_second": 23.556,
      "step": 17500
    },
    {
      "epoch": 0.9466666666666667,
      "grad_norm": 1.343576192855835,
      "learning_rate": 5.644167658327605e-05,
      "loss": 0.2659,
      "step": 17750
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.5972301959991455,
      "learning_rate": 5.537334598135959e-05,
      "loss": 0.2732,
      "step": 18000
    },
    {
      "epoch": 0.9733333333333334,
      "grad_norm": 0.9158376455307007,
      "learning_rate": 5.4302527541531024e-05,
      "loss": 0.2803,
      "step": 18250
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 1.03522527217865,
      "learning_rate": 5.32297170484878e-05,
      "loss": 0.2592,
      "step": 18500
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.9112043976783752,
      "learning_rate": 5.21554112092401e-05,
      "loss": 0.2693,
      "step": 18750
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 3.1183204650878906,
      "learning_rate": 5.108010742313749e-05,
      "loss": 0.2613,
      "step": 19000
    },
    {
      "epoch": 1.0266666666666666,
      "grad_norm": 1.082005262374878,
      "learning_rate": 5.0004303551574946e-05,
      "loss": 0.2604,
      "step": 19250
    },
    {
      "epoch": 1.04,
      "grad_norm": 3.2624874114990234,
      "learning_rate": 4.892849768748508e-05,
      "loss": 0.2659,
      "step": 19500
    },
    {
      "epoch": 1.0533333333333332,
      "grad_norm": 2.285919427871704,
      "learning_rate": 4.785318792472297e-05,
      "loss": 0.2515,
      "step": 19750
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.915137767791748,
      "learning_rate": 4.6778872127450815e-05,
      "loss": 0.2558,
      "step": 20000
    },
    {
      "epoch": 1.0666666666666667,
      "eval_accuracy": 0.8819444444444444,
      "eval_loss": 0.2624204754829407,
      "eval_runtime": 106.5216,
      "eval_samples_per_second": 469.388,
      "eval_steps_per_second": 23.469,
      "step": 20000
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.575919508934021,
      "learning_rate": 4.5706047699628704e-05,
      "loss": 0.2521,
      "step": 20250
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 1.10219407081604,
      "learning_rate": 4.463521135471854e-05,
      "loss": 0.2541,
      "step": 20500
    },
    {
      "epoch": 1.1066666666666667,
      "grad_norm": 0.7168670296669006,
      "learning_rate": 4.356685888570773e-05,
      "loss": 0.268,
      "step": 20750
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9723325967788696,
      "learning_rate": 4.250148493555902e-05,
      "loss": 0.2592,
      "step": 21000
    },
    {
      "epoch": 1.1333333333333333,
      "grad_norm": 1.3458164930343628,
      "learning_rate": 4.143958276819267e-05,
      "loss": 0.2581,
      "step": 21250
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 1.1136043071746826,
      "learning_rate": 4.038164404010726e-05,
      "loss": 0.2598,
      "step": 21500
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.7315237522125244,
      "learning_rate": 3.932815857274468e-05,
      "loss": 0.2716,
      "step": 21750
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 1.697805643081665,
      "learning_rate": 3.827961412570476e-05,
      "loss": 0.2529,
      "step": 22000
    },
    {
      "epoch": 1.1866666666666668,
      "grad_norm": 1.1072660684585571,
      "learning_rate": 3.723649617091448e-05,
      "loss": 0.246,
      "step": 22250
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9248263835906982,
      "learning_rate": 3.619928766785638e-05,
      "loss": 0.2506,
      "step": 22500
    },
    {
      "epoch": 1.2,
      "eval_accuracy": 0.8841597630767999,
      "eval_loss": 0.2631959617137909,
      "eval_runtime": 106.8038,
      "eval_samples_per_second": 468.148,
      "eval_steps_per_second": 23.407,
      "step": 22500
    },
    {
      "epoch": 1.2133333333333334,
      "grad_norm": 2.8024816513061523,
      "learning_rate": 3.5168468839960235e-05,
      "loss": 0.2485,
      "step": 22750
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 2.630967855453491,
      "learning_rate": 3.414451695226157e-05,
      "loss": 0.2533,
      "step": 23000
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0280357599258423,
      "learning_rate": 3.3127906090429774e-05,
      "loss": 0.2545,
      "step": 23250
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 1.0895079374313354,
      "learning_rate": 3.211910694126828e-05,
      "loss": 0.2606,
      "step": 23500
    },
    {
      "epoch": 1.2666666666666666,
      "grad_norm": 0.9614932537078857,
      "learning_rate": 3.111858657478855e-05,
      "loss": 0.254,
      "step": 23750
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.481350064277649,
      "learning_rate": 3.0126808227958426e-05,
      "loss": 0.2453,
      "step": 24000
    },
    {
      "epoch": 1.2933333333333334,
      "grad_norm": 1.0889121294021606,
      "learning_rate": 2.9144231090225248e-05,
      "loss": 0.2444,
      "step": 24250
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 0.9308601021766663,
      "learning_rate": 2.817131009091302e-05,
      "loss": 0.2477,
      "step": 24500
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.143709421157837,
      "learning_rate": 2.7208495688591828e-05,
      "loss": 0.2487,
      "step": 24750
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.703220009803772,
      "learning_rate": 2.6256233662517436e-05,
      "loss": 0.2415,
      "step": 25000
    },
    {
      "epoch": 1.3333333333333333,
      "eval_accuracy": 0.885190448549869,
      "eval_loss": 0.258791983127594,
      "eval_runtime": 106.3272,
      "eval_samples_per_second": 470.247,
      "eval_steps_per_second": 23.512,
      "step": 25000
    },
    {
      "epoch": 1.3466666666666667,
      "grad_norm": 0.84623122215271,
      "learning_rate": 2.531496490623719e-05,
      "loss": 0.2498,
      "step": 25250
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.9231047034263611,
      "learning_rate": 2.4385125223458015e-05,
      "loss": 0.2759,
      "step": 25500
    },
    {
      "epoch": 1.3733333333333333,
      "grad_norm": 1.2116878032684326,
      "learning_rate": 2.346714512627104e-05,
      "loss": 0.243,
      "step": 25750
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 0.767587423324585,
      "learning_rate": 2.2561449635826286e-05,
      "loss": 0.2471,
      "step": 26000
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.887707233428955,
      "learning_rate": 2.1668458085549504e-05,
      "loss": 0.2564,
      "step": 26250
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 1.3384666442871094,
      "learning_rate": 2.0788583926992383e-05,
      "loss": 0.2437,
      "step": 26500
    },
    {
      "epoch": 1.4266666666666667,
      "grad_norm": 2.2163281440734863,
      "learning_rate": 1.992223453840622e-05,
      "loss": 0.2518,
      "step": 26750
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.7472708225250244,
      "learning_rate": 1.906981103612739e-05,
      "loss": 0.2558,
      "step": 27000
    },
    {
      "epoch": 1.4533333333333334,
      "grad_norm": 0.891429603099823,
      "learning_rate": 1.8231708088862053e-05,
      "loss": 0.2535,
      "step": 27250
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.8755138516426086,
      "learning_rate": 1.740831373495607e-05,
      "loss": 0.251,
      "step": 27500
    },
    {
      "epoch": 1.4666666666666668,
      "eval_accuracy": 0.8847639442031741,
      "eval_loss": 0.25733116269111633,
      "eval_runtime": 106.8345,
      "eval_samples_per_second": 468.013,
      "eval_steps_per_second": 23.401,
      "step": 27500
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.1129566431045532,
      "learning_rate": 1.6600009202734827e-05,
      "loss": 0.2477,
      "step": 27750
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 1.229927897453308,
      "learning_rate": 1.5807168733996054e-05,
      "loss": 0.2447,
      "step": 28000
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 1.2042789459228516,
      "learning_rate": 1.50301594107373e-05,
      "loss": 0.2455,
      "step": 28250
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6369622349739075,
      "learning_rate": 1.4269340985198443e-05,
      "loss": 0.2415,
      "step": 28500
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 0.77051842212677,
      "learning_rate": 1.3525065713297813e-05,
      "loss": 0.2464,
      "step": 28750
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 1.7628384828567505,
      "learning_rate": 1.2797678191539153e-05,
      "loss": 0.2541,
      "step": 29000
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.390507221221924,
      "learning_rate": 1.2087515197464749e-05,
      "loss": 0.2521,
      "step": 29250
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 1.2118855714797974,
      "learning_rate": 1.1394905533728762e-05,
      "loss": 0.2553,
      "step": 29500
    },
    {
      "epoch": 1.5866666666666667,
      "grad_norm": 1.3457978963851929,
      "learning_rate": 1.0720169875862896e-05,
      "loss": 0.2487,
      "step": 29750
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4979634284973145,
      "learning_rate": 1.0063620623804949e-05,
      "loss": 0.2623,
      "step": 30000
    },
    {
      "epoch": 1.6,
      "eval_accuracy": 0.886231739043426,
      "eval_loss": 0.2560758888721466,
      "eval_runtime": 107.0346,
      "eval_samples_per_second": 467.139,
      "eval_steps_per_second": 23.357,
      "step": 30000
    }
  ],
  "logging_steps": 250,
  "max_steps": 37500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 2500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
